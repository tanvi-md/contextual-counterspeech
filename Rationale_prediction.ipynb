{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKUqwmKu3t_d"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install ekphrasis\n",
        "!git clone https://github.com/hate-alert/Tutorial-ICWSM-2021.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkJAnGuN_gLB"
      },
      "source": [
        "!cd Tutorial-ICWSM-2021"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTB7UXsm3_mF"
      },
      "source": [
        "import transformers\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import BertForTokenClassification, BertForSequenceClassification,BertPreTrainedModel, BertModel\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import re\n",
        "import random\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from Code.utils import *\n",
        "from Code.model import *\n",
        "from Code.predictions import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjbiE-E6Fl0v"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "   device = torch.device(\"cuda\")\n",
        "else:\n",
        "   device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8_FUrHCC5FQ"
      },
      "source": [
        "model = modelPredRationale(model_path='Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two',device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "dataset = pd.read_csv('https://raw.githubusercontent.com/marcoguerini/CONAN/master/Multitarget-CONAN/Multitarget-CONAN.csv')"
      ],
      "metadata": {
        "id": "zWl1ObtkO74k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.rename(columns = {'HATE_SPEECH':'Sentences'}, inplace = True)"
      ],
      "metadata": {
        "id": "bYJEaGEhO9Cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.rename(columns = {'INDEX':'Index'}, inplace = True)"
      ],
      "metadata": {
        "id": "7hP2DeFcPwOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "en7viZPEmF3j"
      },
      "source": [
        "## provided function by HateXplain authors in demo, which I have slightly modified\n",
        "\n",
        "def getDatasetPrediction(dataset,config):\n",
        "    labels,attention,sents=model.return_rationales(dataset['Sentences'])\n",
        "    predictions = {}\n",
        "    for index,row in dataset.iterrows():\n",
        "        dict1={}\n",
        "        dict_labels={}\n",
        "        for ele in config:\n",
        "            dict_labels[config[ele]]=round(labels[index][ele],3)\n",
        "\n",
        "        dict1[\"Tokens\"] = sents[index]\n",
        "        dict1[\"Rationale\"]=attention[index][0:len(dict1[\"Tokens\"])]\n",
        "        predictions[row['Index']] = dict1\n",
        "    return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_93XaDK9oIU6"
      },
      "source": [
        "config=model.config.id2label\n",
        "predictions2 = getDatasetPrediction(dataset,config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "f = open(\"file.pkl\",\"wb\")\n",
        "\n",
        "pickle.dump(predictions2,f)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "asF69OqsZw2I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}